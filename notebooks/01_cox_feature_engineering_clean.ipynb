{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCGA PANCAN Multi-Omics Data Loading and Cox Regression Feature Engineering\n",
    "\n",
    "This notebook implements comprehensive loading and preprocessing of TCGA PANCAN multi-omics data with Cox regression analysis for feature engineering.\n",
    "\n",
    "## Data Files Structure:\n",
    "1. **Transcriptome**: `unc.edu_PANCAN_IlluminaHiSeq_RNASeqV2.geneExp_whitelisted.tsv`\n",
    "2. **Copy Number Variation**: `CNV.GISTIC_call.all_data_by_genes_whitelisted.tsv`\n",
    "3. **microRNA**: `bcgsc.ca_PANCAN_IlluminaHiSeq_miRNASeq.miRNAExp_whitelisted.tsv`\n",
    "4. **RPPA**: `mdanderson.org_PANCAN_MDA_RPPA_Core.RPPA_whitelisted.tsv`\n",
    "5. **Mutations**: `tcga_pancancer_082115.vep.filter_whitelisted.maf.gz`\n",
    "6. **Clinical**: `clinical_PANCAN_patient_with_followup.tsv`\n",
    "\n",
    "## Output:\n",
    "- Cox coefficient lookup tables\n",
    "- Processed multi-omics data (patient × features)\n",
    "- Feature importance rankings\n",
    "- Data quality reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n",
      "Raw data path: ../data/raw\n",
      "Processed data path: ../data/processed\n",
      "Results path: ../results\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import KaplanMeierFitter\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Define paths\n",
    "DATA_RAW_PATH = Path('../data/raw')\n",
    "DATA_PROCESSED_PATH = Path('../data/processed')\n",
    "RESULTS_PATH = Path('../results')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "DATA_PROCESSED_PATH.mkdir(exist_ok=True)\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"Raw data path: {DATA_RAW_PATH}\")\n",
    "print(f\"Processed data path: {DATA_PROCESSED_PATH}\")\n",
    "print(f\"Results path: {RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_patient_id(patient_id):\n",
    "    \"\"\"Standardize TCGA patient IDs to 12-character format (TCGA-XX-XXXX)\"\"\"\n",
    "    if isinstance(patient_id, str):\n",
    "        # Remove any trailing parts after the sample type (e.g., -01A, -11A)\n",
    "        parts = patient_id.split('-')\n",
    "        if len(parts) >= 3:\n",
    "            return f\"{parts[0]}-{parts[1]}-{parts[2]}\"\n",
    "    return patient_id\n",
    "\n",
    "def load_transcriptome_data(file_path):\n",
    "    \"\"\"Load and preprocess transcriptome data with log2 transformation\"\"\"\n",
    "    print(\"Loading transcriptome data...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep='\\\\t', index_col=0)\n",
    "    \n",
    "    # Parse gene symbols from first column (Gene_Symbol|Entrez_ID)\n",
    "    gene_info = df.index.str.split('|', expand=True)\n",
    "    \n",
    "    # Convert to DataFrame to handle properly\n",
    "    if hasattr(gene_info, 'to_frame'):\n",
    "        gene_info_df = gene_info.to_frame()\n",
    "    else:\n",
    "        gene_info_df = pd.DataFrame(gene_info.tolist(), columns=['gene_symbol', 'entrez_id'])\n",
    "    \n",
    "    # Handle case where gene symbols might be missing (marked as \\\"?\\\")\n",
    "    if gene_info_df.shape[1] >= 2:\n",
    "        gene_symbols = gene_info_df.iloc[:, 0]\n",
    "        entrez_ids = gene_info_df.iloc[:, 1]\n",
    "        \n",
    "        # If gene symbols are \\\"?\\\", use Entrez IDs instead\n",
    "        gene_symbols = gene_symbols.where(gene_symbols != '?', 'Gene_' + entrez_ids.astype(str))\n",
    "    else:\n",
    "        # No \\\"|\\\" separator found, use original index\n",
    "        gene_symbols = df.index\n",
    "        entrez_ids = None\n",
    "    \n",
    "    # Set gene symbols as index\n",
    "    df.index = gene_symbols\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df = df.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df.index = [standardize_patient_id(pid) for pid in df.index]\n",
    "    \n",
    "    # Store original values for comparison\n",
    "    original_stats = {\n",
    "        'mean': df.values.mean(),\n",
    "        'std': df.values.std(),\n",
    "        'min': df.values.min(),\n",
    "        'max': df.values.max(),\n",
    "        'zeros': (df.values == 0).sum()\n",
    "    }\n",
    "    \n",
    "    # Apply log2 transformation: log2(x + 1)\n",
    "    df_log = np.log2(df + 1)\n",
    "    \n",
    "    # Store transformed stats\n",
    "    transformed_stats = {\n",
    "        'mean': df_log.values.mean(),\n",
    "        'std': df_log.values.std(),\n",
    "        'min': df_log.values.min(),\n",
    "        'max': df_log.values.max(),\n",
    "        'zeros': (df_log.values == 0).sum()\n",
    "    }\n",
    "    \n",
    "    transformation_stats = {\n",
    "        'original': original_stats,\n",
    "        'transformed': transformed_stats,\n",
    "        'n_patients': df_log.shape[0],\n",
    "        'n_genes': df_log.shape[1]\n",
    "    }\n",
    "    \n",
    "    print(f\"Transcriptome data loaded: {df_log.shape[0]} patients × {df_log.shape[1]} genes\")\n",
    "    \n",
    "    return df_log, transformation_stats\n",
    "\n",
    "def load_cnv_data(file_path):\n",
    "    \"\"\"Load and preprocess CNV data\"\"\"\n",
    "    print(\"Loading CNV data...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep='\\\\t')\n",
    "    \n",
    "    # Skip first 3 annotation columns and set gene symbol as index\n",
    "    gene_symbols = df.iloc[:, 0]  # First column is Gene Symbol\n",
    "    df_values = df.iloc[:, 3:]  # Skip first 3 columns (Gene Symbol, Locus ID, Cytoband)\n",
    "    df_values.index = gene_symbols\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df_values = df_values.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df_values.index = [standardize_patient_id(pid) for pid in df_values.index]\n",
    "    \n",
    "    print(f\\\"CNV data loaded: {df_values.shape[0]} patients × {df_values.shape[1]} genes\\\")\n",
    "    \n",
    "    return df_values\n",
    "\n",
    "def load_mirna_data(file_path):\n",
    "    \\\"\\\"\\\"Load and preprocess microRNA data\\\"\\\"\\\"\n",
    "    print(\\\"Loading microRNA data...\\\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep='\\\\t', index_col=0)\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df = df.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df.index = [standardize_patient_id(pid) for pid in df.index]\n",
    "    \n",
    "    print(f\\\"microRNA data loaded: {df.shape[0]} patients × {df.shape[1]} miRNAs\\\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_rppa_data(file_path):\n",
    "    \\\"\\\"\\\"Load and preprocess RPPA protein data\\\"\\\"\\\"\n",
    "    print(\\\"Loading RPPA data...\\\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep='\\\\t', index_col=0)\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df = df.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df.index = [standardize_patient_id(pid) for pid in df.index]\n",
    "    \n",
    "    print(f\\\"RPPA data loaded: {df.shape[0]} patients × {df.shape[1]} proteins\\\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_mutation_data(file_path):\n",
    "    \\\"\\\"\\\"Load and preprocess mutation data from MAF format\\\"\\\"\\\"\n",
    "    print(\\\"Loading mutation data...\\\")\n",
    "    \n",
    "    # Load MAF file with encoding handling\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "            df = pd.read_csv(f, sep='\\\\t', low_memory=False)\n",
    "    except UnicodeDecodeError:\n",
    "        with gzip.open(file_path, 'rt', encoding='latin-1') as f:\n",
    "            df = pd.read_csv(f, sep='\\\\t', low_memory=False)\n",
    "    \n",
    "    print(f\\\"Raw MAF data: {df.shape[0]} mutations\\\")\n",
    "    \n",
    "    # Define mutation impact scoring\n",
    "    variant_impact = {\n",
    "        'Silent': 0,\n",
    "        'Missense_Mutation': 1,\n",
    "        'Nonsense_Mutation': 2,\n",
    "        'Frame_Shift_Del': 2,\n",
    "        'Frame_Shift_Ins': 2,\n",
    "        'Splice_Site': 2,\n",
    "        'Translation_Start_Site': 1,\n",
    "        'Nonstop_Mutation': 1,\n",
    "        'In_Frame_Del': 1,\n",
    "        'In_Frame_Ins': 1,\n",
    "        \\\"3'UTR\\\": 0,\n",
    "        \\\"5'UTR\\\": 0,\n",
    "        'Intron': 0,\n",
    "        'RNA': 0\n",
    "    }\n",
    "    \n",
    "    # Filter for relevant columns\n",
    "    required_cols = ['Hugo_Symbol', 'Tumor_Sample_Barcode', 'Variant_Classification']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\\\"Missing required columns. Available: {df.columns.tolist()}\\\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df['Patient_ID'] = df['Tumor_Sample_Barcode'].apply(standardize_patient_id)\n",
    "    \n",
    "    # Map variant classifications to impact scores\n",
    "    df['Impact_Score'] = df['Variant_Classification'].map(variant_impact).fillna(0)\n",
    "    \n",
    "    # Aggregate mutations per patient-gene pair (take maximum impact)\n",
    "    mutation_matrix = df.groupby(['Patient_ID', 'Hugo_Symbol'])['Impact_Score'].max().unstack(fill_value=0)\n",
    "    \n",
    "    print(f\\\"Mutation matrix: {mutation_matrix.shape[0]} patients × {mutation_matrix.shape[1]} genes\\\")\n",
    "    \n",
    "    return mutation_matrix\n",
    "\n",
    "def load_clinical_data(file_path):\n",
    "    \\\"\\\"\\\"Load and preprocess clinical data\\\"\\\"\\\"\n",
    "    print(\\\"Loading clinical data...\\\")\n",
    "    \n",
    "    # Try different encodings to handle problematic characters\n",
    "    encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "    \n",
    "    df = None\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep='\\\\t', encoding=encoding, low_memory=False)\n",
    "            print(f\\\"Successfully loaded clinical data with {encoding} encoding\\\")\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    \n",
    "    if df is None:\n",
    "        # Last resort: ignore problematic characters\n",
    "        df = pd.read_csv(file_path, sep='\\\\t', encoding='utf-8', errors='ignore', low_memory=False)\n",
    "        print(\\\"Loaded clinical data with UTF-8 encoding, ignoring problematic characters\\\")\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df['bcr_patient_barcode'] = df['bcr_patient_barcode'].apply(standardize_patient_id)\n",
    "    \n",
    "    # Set patient ID as index\n",
    "    df = df.set_index('bcr_patient_barcode')\n",
    "    \n",
    "    # Extract survival information\n",
    "    survival_cols = ['vital_status', 'days_to_death', 'days_to_last_followup', 'acronym']\n",
    "    available_cols = [col for col in survival_cols if col in df.columns]\n",
    "    \n",
    "    if 'vital_status' in df.columns:\n",
    "        # Create survival time and event columns\n",
    "        df['survival_time'] = np.where(\n",
    "            df['vital_status'] == 'Dead',\n",
    "            df['days_to_death'] if 'days_to_death' in df.columns else np.nan,\n",
    "            df['days_to_last_followup'] if 'days_to_last_followup' in df.columns else np.nan\n",
    "        )\n",
    "        df['survival_event'] = (df['vital_status'] == 'Dead').astype(int)\n",
    "    \n",
    "    print(f\\\"Clinical data loaded: {df.shape[0]} patients × {df.shape[1]} features\\\")\n",
    "    \n",
    "    return df\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING TCGA PANCAN MULTI-OMICS DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load transcriptome data\n",
    "expression_data, transformation_stats = load_transcriptome_data(\n",
    "    DATA_RAW_PATH / 'unc.edu_PANCAN_IlluminaHiSeq_RNASeqV2.geneExp_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load CNV data\n",
    "cnv_data = load_cnv_data(\n",
    "    DATA_RAW_PATH / 'CNV.GISTIC_call.all_data_by_genes_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load microRNA data\n",
    "mirna_data = load_mirna_data(\n",
    "    DATA_RAW_PATH / 'bcgsc.ca_PANCAN_IlluminaHiSeq_miRNASeq.miRNAExp_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load RPPA data\n",
    "rppa_data = load_rppa_data(\n",
    "    DATA_RAW_PATH / 'mdanderson.org_PANCAN_MDA_RPPA_Core.RPPA_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load mutation data\n",
    "mutation_data = load_mutation_data(\n",
    "    DATA_RAW_PATH / 'tcga_pancancer_082115.vep.filter_whitelisted.maf.gz'\n",
    ")\n",
    "\n",
    "# Load clinical data\n",
    "clinical_data = load_clinical_data(\n",
    "    DATA_RAW_PATH / 'clinical_PANCAN_patient_with_followup.tsv'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA LOADING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Expression: {expression_data.shape[0]} patients × {expression_data.shape[1]} genes\")\n",
    "print(f\"CNV: {cnv_data.shape[0]} patients × {cnv_data.shape[1]} genes\")\n",
    "print(f\"microRNA: {mirna_data.shape[0]} patients × {mirna_data.shape[1]} miRNAs\")\n",
    "print(f\"RPPA: {rppa_data.shape[0]} patients × {rppa_data.shape[1]} proteins\")\n",
    "print(f\"Mutations: {mutation_data.shape[0]} patients × {mutation_data.shape[1]} genes\")\n",
    "print(f\"Clinical: {clinical_data.shape[0]} patients × {clinical_data.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Patient ID Matching and Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patient overlap across datasets\n",
    "datasets = {\n",
    "    'Expression': set(expression_data.index),\n",
    "    'CNV': set(cnv_data.index),\n",
    "    'microRNA': set(mirna_data.index),\n",
    "    'RPPA': set(rppa_data.index),\n",
    "    'Mutations': set(mutation_data.index),\n",
    "    'Clinical': set(clinical_data.index)\n",
    "}\n",
    "\n",
    "print(\"Patient counts per dataset:\")\n",
    "for name, patients in datasets.items():\n",
    "    print(f\"{name}: {len(patients)} patients\")\n",
    "\n",
    "# Find common patients across all datasets\n",
    "common_patients = set.intersection(*datasets.values())\n",
    "print(f\"\\nCommon patients across all datasets: {len(common_patients)}\")\n",
    "\n",
    "# Find common patients with survival data\n",
    "survival_patients = clinical_data.dropna(subset=['survival_time', 'survival_event']).index\n",
    "common_survival_patients = common_patients.intersection(set(survival_patients))\n",
    "print(f\"Common patients with survival data: {len(common_survival_patients)}\")\n",
    "\n",
    "# Create overlap visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot patient counts\n",
    "plt.subplot(2, 3, 1)\n",
    "dataset_counts = [len(patients) for patients in datasets.values()]\n",
    "plt.bar(range(len(datasets)), dataset_counts)\n",
    "plt.xticks(range(len(datasets)), list(datasets.keys()), rotation=45)\n",
    "plt.title('Patient Counts by Dataset')\n",
    "plt.ylabel('Number of Patients')\n",
    "\n",
    "# Plot cancer type distribution\n",
    "if 'acronym' in clinical_data.columns:\n",
    "    cancer_counts = clinical_data.loc[common_survival_patients, 'acronym'].value_counts()\n",
    "    plt.subplot(2, 3, 2)\n",
    "    cancer_counts.head(15).plot(kind='bar')\n",
    "    plt.title('Cancer Types (Common Patients)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Patient Count')\n",
    "\n",
    "# Plot survival data quality\n",
    "if 'survival_time' in clinical_data.columns:\n",
    "    plt.subplot(2, 3, 3)\n",
    "    survival_times = clinical_data.loc[common_survival_patients, 'survival_time']\n",
    "    plt.hist(survival_times.dropna(), bins=50, alpha=0.7)\n",
    "    plt.title('Survival Time Distribution')\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Patient Count')\n",
    "\n",
    "# Plot survival events\n",
    "if 'survival_event' in clinical_data.columns:\n",
    "    plt.subplot(2, 3, 4)\n",
    "    event_counts = clinical_data.loc[common_survival_patients, 'survival_event'].value_counts()\n",
    "    plt.pie(event_counts.values, labels=['Censored', 'Death'], autopct='%1.1f%%')\n",
    "    plt.title('Survival Events')\n",
    "\n",
    "# Plot data completeness heatmap\n",
    "plt.subplot(2, 3, 5)\n",
    "completeness_data = []\n",
    "for patient in sorted(list(common_patients))[:100]:  # Show first 100 patients\n",
    "    row = [1 if patient in datasets[name] else 0 for name in datasets.keys()]\n",
    "    completeness_data.append(row)\n",
    "\n",
    "completeness_df = pd.DataFrame(completeness_data, columns=list(datasets.keys()))\n",
    "sns.heatmap(completeness_df.T, cmap='RdYlBu_r', cbar_kws={'label': 'Data Available'})\n",
    "plt.title('Data Completeness (First 100 Patients)')\n",
    "plt.xlabel('Patients')\n",
    "\n",
    "# Plot transformation stats for expression data\n",
    "plt.subplot(2, 3, 6)\n",
    "original_mean = transformation_stats['original']['mean']\n",
    "transformed_mean = transformation_stats['transformed']['mean']\n",
    "plt.bar(['Original', 'Log2+1'], [original_mean, transformed_mean])\n",
    "plt.title('Expression Data Transformation')\n",
    "plt.ylabel('Mean Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Store common patients for further analysis\n",
    "print(f\"\\nUsing {len(common_survival_patients)} patients with complete omics and survival data\")\n",
    "final_patient_list = sorted(list(common_survival_patients))\n",
    "\n",
    "# Display transformation statistics\n",
    "print(f\"\\nExpression Data Transformation Statistics:\")\n",
    "print(f\"Original data - Mean: {transformation_stats['original']['mean']:.3f}, Std: {transformation_stats['original']['std']:.3f}\")\n",
    "print(f\"Transformed data - Mean: {transformation_stats['transformed']['mean']:.3f}, Std: {transformation_stats['transformed']['std']:.3f}\")\n",
    "print(f\"Zero values - Original: {transformation_stats['original']['zeros']}, Transformed: {transformation_stats['transformed']['zeros']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cox Regression Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cox_regression_by_cancer(omics_data, clinical_data, omics_type, min_patients=20, p_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Perform Cox regression analysis by cancer type for given omics data\n",
    "    \n",
    "    Parameters:\n",
    "    - omics_data: DataFrame with patients as rows, features as columns\n",
    "    - clinical_data: DataFrame with survival information\n",
    "    - omics_type: String identifier for the omics type\n",
    "    - min_patients: Minimum number of patients required per cancer type\n",
    "    - p_threshold: P-value threshold for significance\n",
    "    \n",
    "    Returns:\n",
    "    - cox_results: Dictionary with results by cancer type\n",
    "    - summary_stats: Overall summary statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nPerforming Cox regression analysis for {omics_type} data...\")\n",
    "    \n",
    "    # Filter for common patients\n",
    "    common_patients = list(set(omics_data.index).intersection(set(clinical_data.index)))\n",
    "    \n",
    "    # Get survival data for common patients\n",
    "    survival_data = clinical_data.loc[common_patients, ['survival_time', 'survival_event', 'acronym']].copy()\n",
    "    survival_data = survival_data.dropna()\n",
    "    \n",
    "    # Filter omics data for patients with survival data\n",
    "    omics_filtered = omics_data.loc[survival_data.index].copy()\n",
    "    \n",
    "    print(f\"Analysis dataset: {len(survival_data)} patients with {omics_filtered.shape[1]} features\")\n",
    "    \n",
    "    # Group by cancer type\n",
    "    cancer_types = survival_data['acronym'].value_counts()\n",
    "    valid_cancers = cancer_types[cancer_types >= min_patients].index\n",
    "    \n",
    "    print(f\"Cancer types with >= {min_patients} patients: {len(valid_cancers)}\")\n",
    "    \n",
    "    cox_results = {}\n",
    "    summary_stats = {\n",
    "        'total_features': omics_filtered.shape[1],\n",
    "        'total_patients': len(survival_data),\n",
    "        'cancer_types': len(valid_cancers),\n",
    "        'significant_features': {},\n",
    "        'top_features': {}\n",
    "    }\n",
    "    \n",
    "    for cancer in tqdm(valid_cancers, desc=f\"Processing {omics_type}\"):\n",
    "        # Get patients for this cancer type\n",
    "        cancer_patients = survival_data[survival_data['acronym'] == cancer].index\n",
    "        \n",
    "        # Get omics and survival data for this cancer\n",
    "        cancer_omics = omics_filtered.loc[cancer_patients]\n",
    "        cancer_survival = survival_data.loc[cancer_patients, ['survival_time', 'survival_event']]\n",
    "        \n",
    "        # Remove features with zero variance\n",
    "        feature_vars = cancer_omics.var()\n",
    "        valid_features = feature_vars[feature_vars > 0].index\n",
    "        cancer_omics_filtered = cancer_omics[valid_features]\n",
    "        \n",
    "        print(f\"\\n{cancer}: {len(cancer_patients)} patients, {len(valid_features)} variable features\")\n",
    "        \n",
    "        # Perform univariate Cox regression for each feature\n",
    "        feature_results = []\n",
    "        \n",
    "        for feature in valid_features:\n",
    "            try:\n",
    "                # Create dataframe for Cox regression\n",
    "                cox_data = pd.DataFrame({\n",
    "                    'T': cancer_survival['survival_time'],\n",
    "                    'E': cancer_survival['survival_event'],\n",
    "                    feature: cancer_omics_filtered[feature]\n",
    "                })\n",
    "                \n",
    "                # Remove rows with missing data\n",
    "                cox_data = cox_data.dropna()\n",
    "                \n",
    "                if len(cox_data) < 5:  # Need at least 5 observations\n",
    "                    continue\n",
    "                \n",
    "                # Fit Cox model\n",
    "                cph = CoxPHFitter()\n",
    "                cph.fit(cox_data, duration_col='T', event_col='E')\n",
    "                \n",
    "                # Extract results\n",
    "                coef = cph.summary.loc[feature, 'coef']\n",
    "                p_value = cph.summary.loc[feature, 'p']\n",
    "                hr = np.exp(coef)\n",
    "                ci_lower = np.exp(cph.summary.loc[feature, 'coef lower 95%'])\n",
    "                ci_upper = np.exp(cph.summary.loc[feature, 'coef upper 95%'])\n",
    "                \n",
    "                feature_results.append({\n",
    "                    'feature': feature,\n",
    "                    'coef': coef,\n",
    "                    'hr': hr,\n",
    "                    'p_value': p_value,\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'n_patients': len(cox_data)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Skip problematic features\n",
    "                continue\n",
    "        \n",
    "        # Convert to DataFrame and sort by p-value\n",
    "        if feature_results:\n",
    "            results_df = pd.DataFrame(feature_results)\n",
    "            results_df = results_df.sort_values('p_value')\n",
    "            \n",
    "            # Count significant features\n",
    "            significant_count = sum(results_df['p_value'] < p_threshold)\n",
    "            \n",
    "            cox_results[cancer] = results_df\n",
    "            summary_stats['significant_features'][cancer] = significant_count\n",
    "            summary_stats['top_features'][cancer] = results_df.head(10)\n",
    "            \n",
    "            print(f\"  Significant features (p < {p_threshold}): {significant_count}/{len(results_df)}\")\n",
    "        else:\n",
    "            print(f\"  No valid results for {cancer}\")\n",
    "    \n",
    "    return cox_results, summary_stats\n",
    "\n",
    "def create_cox_coefficient_lookup(cox_results_dict, omics_types):\n",
    "    \"\"\"Create a comprehensive Cox coefficient lookup table\"\"\"\n",
    "    \n",
    "    print(\"\\nCreating Cox coefficient lookup tables...\")\n",
    "    \n",
    "    # Initialize lookup dictionary\n",
    "    lookup_tables = {}\n",
    "    \n",
    "    for omics_type in omics_types:\n",
    "        if omics_type in cox_results_dict:\n",
    "            print(f\"\\nProcessing {omics_type} results...\")\n",
    "            \n",
    "            # Combine all cancer type results\n",
    "            all_results = []\n",
    "            \n",
    "            for cancer, results_df in cox_results_dict[omics_type].items():\n",
    "                if not results_df.empty:\n",
    "                    results_copy = results_df.copy()\n",
    "                    results_copy['cancer_type'] = cancer\n",
    "                    results_copy['omics_type'] = omics_type\n",
    "                    all_results.append(results_copy)\n",
    "            \n",
    "            if all_results:\n",
    "                combined_df = pd.concat(all_results, ignore_index=True)\n",
    "                \n",
    "                # Create pivot table: features × cancer_types with coefficients\n",
    "                pivot_coef = combined_df.pivot_table(\n",
    "                    index='feature', \n",
    "                    columns='cancer_type', \n",
    "                    values='coef', \n",
    "                    fill_value=0\n",
    "                )\n",
    "                \n",
    "                # Create pivot table for p-values\n",
    "                pivot_pval = combined_df.pivot_table(\n",
    "                    index='feature', \n",
    "                    columns='cancer_type', \n",
    "                    values='p_value', \n",
    "                    fill_value=1\n",
    "                )\n",
    "                \n",
    "                # Create summary statistics per feature\n",
    "                feature_stats = combined_df.groupby('feature').agg({\n",
    "                    'coef': ['mean', 'std', 'count'],\n",
    "                    'p_value': ['min', 'mean'],\n",
    "                    'hr': ['mean']\n",
    "                }).round(4)\n",
    "                \n",
    "                # Flatten column names\n",
    "                feature_stats.columns = ['_'.join(col).strip() for col in feature_stats.columns]\n",
    "                \n",
    "                lookup_tables[omics_type] = {\n",
    "                    'coefficients': pivot_coef,\n",
    "                    'p_values': pivot_pval,\n",
    "                    'feature_stats': feature_stats,\n",
    "                    'raw_results': combined_df\n",
    "                }\n",
    "                \n",
    "                print(f\"  {omics_type}: {len(pivot_coef)} features across {len(pivot_coef.columns)} cancer types\")\n",
    "    \n",
    "    return lookup_tables\n",
    "\n",
    "def visualize_cox_results(cox_results, omics_type, top_n=20):\n",
    "    \"\"\"Visualize Cox regression results\"\"\"\n",
    "    \n",
    "    # Combine results across cancer types\n",
    "    all_results = []\n",
    "    for cancer, results_df in cox_results.items():\n",
    "        if not results_df.empty:\n",
    "            results_copy = results_df.copy()\n",
    "            results_copy['cancer_type'] = cancer\n",
    "            all_results.append(results_copy)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(f\"No results to visualize for {omics_type}\")\n",
    "        return\n",
    "    \n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(f'Cox Regression Results: {omics_type}', fontsize=16)\n",
    "    \n",
    "    # 1. P-value distribution\n",
    "    axes[0, 0].hist(combined_df['p_value'], bins=50, alpha=0.7)\n",
    "    axes[0, 0].axvline(x=0.05, color='red', linestyle='--', label='p=0.05')\n",
    "    axes[0, 0].set_xlabel('P-value')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('P-value Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Coefficient distribution\n",
    "    axes[0, 1].hist(combined_df['coef'], bins=50, alpha=0.7)\n",
    "    axes[0, 1].axvline(x=0, color='red', linestyle='--', label='coef=0')\n",
    "    axes[0, 1].set_xlabel('Cox Coefficient')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Coefficient Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 3. Top significant features\n",
    "    significant_features = combined_df[combined_df['p_value'] < 0.05]\n",
    "    if len(significant_features) > 0:\n",
    "        top_features = significant_features.nsmallest(top_n, 'p_value')\n",
    "        \n",
    "        # Create a color map for cancer types\n",
    "        cancer_types = top_features['cancer_type'].unique()\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(cancer_types)))\n",
    "        color_map = dict(zip(cancer_types, colors))\n",
    "        \n",
    "        scatter_colors = [color_map[cancer] for cancer in top_features['cancer_type']]\n",
    "        \n",
    "        scatter = axes[1, 0].scatter(top_features['coef'], -np.log10(top_features['p_value']), \n",
    "                                   c=scatter_colors, alpha=0.7)\n",
    "        axes[1, 0].axhline(y=-np.log10(0.05), color='red', linestyle='--', label='p=0.05')\n",
    "        axes[1, 0].axvline(x=0, color='red', linestyle='--')\n",
    "        axes[1, 0].set_xlabel('Cox Coefficient')\n",
    "        axes[1, 0].set_ylabel('-log10(p-value)')\n",
    "        axes[1, 0].set_title(f'Top {top_n} Significant Features')\n",
    "        \n",
    "        # Add legend for cancer types\n",
    "        legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                    markerfacecolor=color_map[cancer], markersize=8, label=cancer)\n",
    "                         for cancer in cancer_types[:10]]  # Limit legend size\n",
    "        axes[1, 0].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # 4. Significant features by cancer type\n",
    "    cancer_sig_counts = combined_df[combined_df['p_value'] < 0.05]['cancer_type'].value_counts()\n",
    "    if len(cancer_sig_counts) > 0:\n",
    "        cancer_sig_counts.head(15).plot(kind='bar', ax=axes[1, 1])\n",
    "        axes[1, 1].set_xlabel('Cancer Type')\n",
    "        axes[1, 1].set_ylabel('Significant Features')\n",
    "        axes[1, 1].set_title('Significant Features by Cancer')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    total_tests = len(combined_df)\n",
    "    significant_tests = len(combined_df[combined_df['p_value'] < 0.05])\n",
    "    \n",
    "    print(f\"\\n{omics_type} Summary:\")\n",
    "    print(f\"Total tests: {total_tests:,}\")\n",
    "    print(f\"Significant tests (p < 0.05): {significant_tests:,} ({100*significant_tests/total_tests:.1f}%)\")\n",
    "    print(f\"Cancer types analyzed: {combined_df['cancer_type'].nunique()}\")\n",
    "    print(f\"Unique features tested: {combined_df['feature'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform Cox Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare filtered datasets for analysis\n",
    "filtered_data = {}\n",
    "\n",
    "# Filter all datasets to common patients with survival data\n",
    "for name, data in [\n",
    "    ('Expression', expression_data),\n",
    "    ('CNV', cnv_data),\n",
    "    ('microRNA', mirna_data),\n",
    "    ('RPPA', rppa_data),\n",
    "    ('Mutations', mutation_data)\n",
    "]:\n",
    "    # Filter to common survival patients\n",
    "    common_patients_data = data.loc[final_patient_list]\n",
    "    filtered_data[name] = common_patients_data\n",
    "    print(f\"{name}: {common_patients_data.shape[0]} patients × {common_patients_data.shape[1]} features\")\n",
    "\n",
    "# Also filter clinical data\n",
    "filtered_clinical = clinical_data.loc[final_patient_list]\n",
    "print(f\"Clinical: {filtered_clinical.shape[0]} patients × {filtered_clinical.shape[1]} features\")\n",
    "\n",
    "print(f\"\\\\nAll datasets now have {len(final_patient_list)} patients with complete omics and survival data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Cox regression analysis for each omics type\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMING COX REGRESSION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Store all results\n",
    "all_cox_results = {}\n",
    "all_summary_stats = {}\n",
    "\n",
    "# Define omics types and their corresponding data\n",
    "omics_data_map = {\n",
    "    'Expression': filtered_data['Expression'],\n",
    "    'CNV': filtered_data['CNV'],\n",
    "    'microRNA': filtered_data['microRNA'],\n",
    "    'RPPA': filtered_data['RPPA'],\n",
    "    'Mutations': filtered_data['Mutations']\n",
    "}\n",
    "\n",
    "# Run Cox regression for each omics type\n",
    "for omics_type, omics_data in omics_data_map.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing {omics_type}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Perform Cox regression analysis\n",
    "    cox_results, summary_stats = perform_cox_regression_by_cancer(\n",
    "        omics_data=omics_data,\n",
    "        clinical_data=filtered_clinical,\n",
    "        omics_type=omics_type,\n",
    "        min_patients=20,  # Minimum 20 patients per cancer type\n",
    "        p_threshold=0.05\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    all_cox_results[omics_type] = cox_results\n",
    "    all_summary_stats[omics_type] = summary_stats\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\n{omics_type} Analysis Summary:\")\n",
    "    print(f\"  Total features analyzed: {summary_stats['total_features']:,}\")\n",
    "    print(f\"  Total patients: {summary_stats['total_patients']:,}\")\n",
    "    print(f\"  Cancer types analyzed: {summary_stats['cancer_types']}\")\n",
    "    \n",
    "    # Display significant features by cancer type\n",
    "    if summary_stats['significant_features']:\n",
    "        print(f\"  Significant features by cancer type:\")\n",
    "        for cancer, count in summary_stats['significant_features'].items():\n",
    "            print(f\"    {cancer}: {count} significant features\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COX REGRESSION ANALYSIS COMPLETED\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Cox Coefficient Lookup Tables and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive lookup tables\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREATING COX COEFFICIENT LOOKUP TABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create lookup tables for all omics types\n",
    "omics_types = list(all_cox_results.keys())\n",
    "lookup_tables = create_cox_coefficient_lookup(all_cox_results, omics_types)\n",
    "\n",
    "# Visualize results for each omics type\n",
    "for omics_type in omics_types:\n",
    "    if omics_type in all_cox_results and all_cox_results[omics_type]:\n",
    "        print(f\"\\nVisualizing {omics_type} results...\")\n",
    "        visualize_cox_results(all_cox_results[omics_type], omics_type, top_n=20)\n",
    "\n",
    "# Save all results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING PROCESSED DATA AND RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save lookup tables\n",
    "for omics_type, tables in lookup_tables.items():\n",
    "    # Save coefficient matrix\n",
    "    coef_file = DATA_PROCESSED_PATH / f'cox_coefficients_{omics_type.lower()}.parquet'\n",
    "    tables['coefficients'].to_parquet(coef_file)\n",
    "    print(f\"Saved {omics_type} coefficients: {coef_file}\")\n",
    "    \n",
    "    # Save p-values matrix\n",
    "    pval_file = DATA_PROCESSED_PATH / f'cox_pvalues_{omics_type.lower()}.parquet'\n",
    "    tables['p_values'].to_parquet(pval_file)\n",
    "    print(f\"Saved {omics_type} p-values: {pval_file}\")\n",
    "    \n",
    "    # Save feature statistics\n",
    "    stats_file = DATA_PROCESSED_PATH / f'cox_feature_stats_{omics_type.lower()}.parquet'\n",
    "    tables['feature_stats'].to_parquet(stats_file)\n",
    "    print(f\"Saved {omics_type} feature stats: {stats_file}\")\n",
    "    \n",
    "    # Save raw results\n",
    "    raw_file = DATA_PROCESSED_PATH / f'cox_raw_results_{omics_type.lower()}.parquet'\n",
    "    tables['raw_results'].to_parquet(raw_file)\n",
    "    print(f\"Saved {omics_type} raw results: {raw_file}\")\n",
    "\n",
    "# Save processed omics data\n",
    "for omics_type, data in filtered_data.items():\n",
    "    processed_file = DATA_PROCESSED_PATH / f'processed_{omics_type.lower()}_data.parquet'\n",
    "    data.to_parquet(processed_file)\n",
    "    print(f\"Saved processed {omics_type} data: {processed_file}\")\n",
    "\n",
    "# Save processed clinical data\n",
    "clinical_file = DATA_PROCESSED_PATH / 'processed_clinical_data.parquet'\n",
    "filtered_clinical.to_parquet(clinical_file)\n",
    "print(f\"Saved processed clinical data: {clinical_file}\")\n",
    "\n",
    "# Save analysis summary\n",
    "summary_file = RESULTS_PATH / 'cox_analysis_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    # Convert numpy types to native Python types for JSON serialization\n",
    "    summary_for_json = {}\n",
    "    for omics_type, stats in all_summary_stats.items():\n",
    "        summary_for_json[omics_type] = {\n",
    "            'total_features': int(stats['total_features']),\n",
    "            'total_patients': int(stats['total_patients']),\n",
    "            'cancer_types': int(stats['cancer_types']),\n",
    "            'significant_features': {k: int(v) for k, v in stats['significant_features'].items()}\n",
    "        }\n",
    "    \n",
    "    json.dump(summary_for_json, f, indent=2)\n",
    "print(f\"Saved analysis summary: {summary_file}\")\n",
    "\n",
    "# Save transformation statistics\n",
    "transform_file = RESULTS_PATH / 'transformation_stats.json'\n",
    "with open(transform_file, 'w') as f:\n",
    "    # Convert numpy types to native Python types\n",
    "    transform_for_json = {}\n",
    "    for key, value in transformation_stats.items():\n",
    "        if isinstance(value, dict):\n",
    "            transform_for_json[key] = {k: float(v) for k, v in value.items()}\n",
    "        else:\n",
    "            transform_for_json[key] = int(value) if isinstance(value, (int, np.integer)) else float(value)\n",
    "    \n",
    "    json.dump(transform_for_json, f, indent=2)\n",
    "print(f\"Saved transformation stats: {transform_file}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL DATA PROCESSING AND ANALYSIS COMPLETED!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Processed data saved to: {DATA_PROCESSED_PATH}\")\n",
    "print(f\"Analysis results saved to: {RESULTS_PATH}\")\n",
    "print(f\"Total patients analyzed: {len(final_patient_list)}\")\n",
    "print(f\"Omics types processed: {', '.join(omics_types)}\")\n",
    "\n",
    "# Display final summary\n",
    "print(f\"\\nFinal Analysis Summary:\")\n",
    "for omics_type, stats in all_summary_stats.items():\n",
    "    total_significant = sum(stats['significant_features'].values())\n",
    "    print(f\"  {omics_type}:\")\n",
    "    print(f\"    - Features: {stats['total_features']:,}\")\n",
    "    print(f\"    - Cancer types: {stats['cancer_types']}\")\n",
    "    print(f\"    - Significant features: {total_significant:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
