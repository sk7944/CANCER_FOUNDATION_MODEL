{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCGA PANCAN Multi-Omics Data Loading and Cox Regression Feature Engineering\n",
    "\n",
    "This notebook implements comprehensive loading and preprocessing of TCGA PANCAN multi-omics data with Cox regression analysis for feature engineering.\n",
    "\n",
    "## Data Files Structure:\n",
    "1. **Transcriptome**: `unc.edu_PANCAN_IlluminaHiSeq_RNASeqV2.geneExp_whitelisted.tsv` (log2 transformed)\n",
    "2. **Copy Number Variation**: `CNV.GISTIC_call.all_data_by_genes_whitelisted.tsv` (log2 transformed)\n",
    "3. **microRNA**: `bcgsc.ca_PANCAN_IlluminaHiSeq_miRNASeq.miRNAExp_whitelisted.tsv` (log2 transformed)\n",
    "4. **RPPA**: `mdanderson.org_PANCAN_MDA_RPPA_Core.RPPA_whitelisted.tsv` (log2 transformed)\n",
    "5. **Methylation**: `jhu-usc.edu_PANCAN_HumanMethylation450.betaValue_whitelisted.csv` (NO transformation, for tab-transformer)\n",
    "6. **Mutations**: `tcga_pancancer_082115.vep.filter_whitelisted.maf.gz` (impact scores, NO transformation)\n",
    "7. **Clinical**: `clinical_PANCAN_patient_with_followup.tsv`\n",
    "\n",
    "## Output:\n",
    "- Cox coefficient lookup tables\n",
    "- Processed multi-omics data (patient × features)\n",
    "- Methylation data for tab-transformer\n",
    "- Feature importance rankings\n",
    "- Data quality reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n",
      "Raw data path: ../data/raw\n",
      "Processed data path: ../data/processed\n",
      "Results path: ../results\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines import KaplanMeierFitter\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Define paths\n",
    "DATA_RAW_PATH = Path('../data/raw')\n",
    "DATA_PROCESSED_PATH = Path('../data/processed')\n",
    "RESULTS_PATH = Path('../results')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "DATA_PROCESSED_PATH.mkdir(exist_ok=True)\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"Raw data path: {DATA_RAW_PATH}\")\n",
    "print(f\"Processed data path: {DATA_PROCESSED_PATH}\")\n",
    "print(f\"Results path: {RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_patient_id(patient_id):\n",
    "    \"\"\"Standardize TCGA patient IDs to 12-character format (TCGA-XX-XXXX)\"\"\"\n",
    "    if isinstance(patient_id, str):\n",
    "        # Remove any trailing parts after the sample type (e.g., -01A, -11A)\n",
    "        parts = patient_id.split('-')\n",
    "        if len(parts) >= 3:\n",
    "            return f\"{parts[0]}-{parts[1]}-{parts[2]}\"\n",
    "    return patient_id\n",
    "\n",
    "def load_transcriptome_data(file_path):\n",
    "    \"\"\"Load and preprocess transcriptome data with log2 transformation\"\"\"\n",
    "    print(\"Loading transcriptome data...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "    \n",
    "    # Parse gene symbols from first column (Gene_Symbol|Entrez_ID)\n",
    "    gene_info = df.index.str.split('|', expand=True)\n",
    "    \n",
    "    # Handle potential IndexError\n",
    "    if hasattr(gene_info, 'shape') and len(gene_info.shape) > 1 and gene_info.shape[1] >= 2:\n",
    "        gene_symbols = gene_info.iloc[:, 0]\n",
    "        entrez_ids = gene_info.iloc[:, 1]\n",
    "        gene_symbols = gene_symbols.where(gene_symbols != '?', 'Gene_' + entrez_ids.astype(str))\n",
    "    else:\n",
    "        # No \"|\" separator found, use original index\n",
    "        gene_symbols = df.index\n",
    "        print(\"Gene symbols not split - using original index\")\n",
    "    \n",
    "    # Set gene symbols as index\n",
    "    df.index = gene_symbols\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df = df.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df.index = [standardize_patient_id(pid) for pid in df.index]\n",
    "    \n",
    "    # Store original values for comparison\n",
    "    original_stats = {\n",
    "        'mean': df.values.mean(),\n",
    "        'std': df.values.std(),\n",
    "        'min': df.values.min(),\n",
    "        'max': df.values.max(),\n",
    "        'zeros': (df.values == 0).sum()\n",
    "    }\n",
    "    \n",
    "    # Apply log2 transformation: log2(x + 1)\n",
    "    df_log = np.log2(df + 1)\n",
    "    \n",
    "    # Store transformed stats\n",
    "    transformed_stats = {\n",
    "        'mean': df_log.values.mean(),\n",
    "        'std': df_log.values.std(),\n",
    "        'min': df_log.values.min(),\n",
    "        'max': df_log.values.max(),\n",
    "        'zeros': (df_log.values == 0).sum()\n",
    "    }\n",
    "    \n",
    "    transformation_stats = {\n",
    "        'original': original_stats,\n",
    "        'transformed': transformed_stats,\n",
    "        'n_patients': df_log.shape[0],\n",
    "        'n_genes': df_log.shape[1]\n",
    "    }\n",
    "    \n",
    "    print(f\"Transcriptome data loaded: {df_log.shape[0]} patients × {df_log.shape[1]} genes (log2 transformed)\")\n",
    "    \n",
    "    return df_log, transformation_stats\n",
    "\n",
    "def load_cnv_data(file_path):\n",
    "    \"\"\"Load and preprocess CNV data with log2 transformation\"\"\"\n",
    "    print(\"Loading CNV data...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "    \n",
    "    # Skip first 3 annotation columns and set gene symbol as index\n",
    "    gene_symbols = df.iloc[:, 0]  # First column is Gene Symbol\n",
    "    df_values = df.iloc[:, 3:]  # Skip first 3 columns (Gene Symbol, Locus ID, Cytoband)\n",
    "    df_values.index = gene_symbols\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df_values = df_values.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df_values.index = [standardize_patient_id(pid) for pid in df_values.index]\n",
    "    \n",
    "    # Apply log2 transformation: log2(x + 1) for positive values, handle negatives\n",
    "    min_val = df_values.values.min()\n",
    "    if min_val < 0:\n",
    "        # Shift negative values to make all positive before log transformation\n",
    "        df_log = np.log2(df_values - min_val + 1)\n",
    "        print(f\"Applied log2(x - {min_val:.3f} + 1) transformation for negative CNV values\")\n",
    "    else:\n",
    "        df_log = np.log2(df_values + 1)\n",
    "        print(\"Applied log2(x + 1) transformation\")\n",
    "    \n",
    "    print(f\"CNV data loaded: {df_log.shape[0]} patients × {df_log.shape[1]} genes (log2 transformed)\")\n",
    "    \n",
    "    return df_log\n",
    "\n",
    "def load_mirna_data(file_path):\n",
    "    \"\"\"Load and preprocess microRNA data with log2 transformation\"\"\"\n",
    "    print(\"Loading microRNA data...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df = df.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df.index = [standardize_patient_id(pid) for pid in df.index]\n",
    "    \n",
    "    # Apply log2 transformation: log2(x + 1)\n",
    "    df_log = np.log2(df + 1)\n",
    "    \n",
    "    print(f\"microRNA data loaded: {df_log.shape[0]} patients × {df_log.shape[1]} miRNAs (log2 transformed)\")\n",
    "    \n",
    "    return df_log\n",
    "\n",
    "def load_rppa_data(file_path):\n",
    "    \"\"\"Load and preprocess RPPA protein data with log2 transformation\"\"\"\n",
    "    print(\"Loading RPPA data...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df = df.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df.index = [standardize_patient_id(pid) for pid in df.index]\n",
    "    \n",
    "    # Apply log2 transformation: log2(x + 1) for positive values, handle negatives\n",
    "    min_val = df.values.min()\n",
    "    if min_val < 0:\n",
    "        # Shift negative values to make all positive before log transformation\n",
    "        df_log = np.log2(df - min_val + 1)\n",
    "        print(f\"Applied log2(x - {min_val:.3f} + 1) transformation for negative RPPA values\")\n",
    "    else:\n",
    "        df_log = np.log2(df + 1)\n",
    "        print(\"Applied log2(x + 1) transformation\")\n",
    "    \n",
    "    print(f\"RPPA data loaded: {df_log.shape[0]} patients × {df_log.shape[1]} proteins (log2 transformed)\")\n",
    "    \n",
    "    return df_log\n",
    "\n",
    "def load_methylation_data(file_path):\n",
    "    \"\"\"Load methylation data for tab-transformer (NO log2 transformation)\"\"\"\n",
    "    print(\"Loading methylation data...\")\n",
    "    print(\"Note: NO log2 transformation applied - beta values (0-1) for tab-transformer\")\n",
    "    \n",
    "    # Load data - try both .csv and .tsv extensions\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "    except FileNotFoundError:\n",
    "        # Try with .csv extension\n",
    "        csv_path = str(file_path).replace('.tsv', '.csv')\n",
    "        df = pd.read_csv(csv_path, sep='\\t', index_col=0)\n",
    "    \n",
    "    # Transpose to get patients as rows\n",
    "    df = df.T\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df.index = [standardize_patient_id(pid) for pid in df.index]\n",
    "    \n",
    "    # Check data quality\n",
    "    missing_values = df.isna().sum().sum()\n",
    "    total_values = df.shape[0] * df.shape[1]\n",
    "    missing_percentage = (missing_values / total_values) * 100\n",
    "    \n",
    "    print(f\"Methylation data loaded: {df.shape[0]} patients × {df.shape[1]} probes\")\n",
    "    print(f\"Missing values: {missing_values:,} ({missing_percentage:.2f}% of total)\")\n",
    "    print(\"This data is prepared for tab-transformer network (beta values preserved)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_mutation_data(file_path):\n",
    "    \"\"\"Load and preprocess mutation data from MAF format (NO log2 transformation)\"\"\"\n",
    "    print(\"Loading mutation data...\")\n",
    "    print(\"Note: Impact scores (0-2), NO log2 transformation\")\n",
    "    \n",
    "    # Load MAF file with encoding handling, skipping the version line\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "            # Skip the first line (#version 2.4)\n",
    "            first_line = f.readline()\n",
    "            if first_line.startswith('#version'):\n",
    "                # Read the rest of the file\n",
    "                df = pd.read_csv(f, sep='\\t', low_memory=False)\n",
    "            else:\n",
    "                # Reset file pointer and read normally\n",
    "                f.seek(0)\n",
    "                df = pd.read_csv(f, sep='\\t', low_memory=False)\n",
    "    except UnicodeDecodeError:\n",
    "        with gzip.open(file_path, 'rt', encoding='latin-1') as f:\n",
    "            first_line = f.readline()\n",
    "            if first_line.startswith('#version'):\n",
    "                df = pd.read_csv(f, sep='\\t', low_memory=False)\n",
    "            else:\n",
    "                f.seek(0)\n",
    "                df = pd.read_csv(f, sep='\\t', low_memory=False)\n",
    "    \n",
    "    print(f\"Raw MAF data: {df.shape[0]} mutations\")\n",
    "    \n",
    "    # Define mutation impact scoring\n",
    "    variant_impact = {\n",
    "        'Silent': 0,\n",
    "        'Missense_Mutation': 1,\n",
    "        'Nonsense_Mutation': 2,\n",
    "        'Frame_Shift_Del': 2,\n",
    "        'Frame_Shift_Ins': 2,\n",
    "        'Splice_Site': 2,\n",
    "        'Translation_Start_Site': 1,\n",
    "        'Nonstop_Mutation': 1,\n",
    "        'In_Frame_Del': 1,\n",
    "        'In_Frame_Ins': 1,\n",
    "        \"3'UTR\": 0,\n",
    "        \"5'UTR\": 0,\n",
    "        'Intron': 0,\n",
    "        'RNA': 0\n",
    "    }\n",
    "    \n",
    "    # Filter for relevant columns\n",
    "    required_cols = ['Hugo_Symbol', 'Tumor_Sample_Barcode', 'Variant_Classification']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"Missing required columns. Available columns: {list(df.columns[:10])}...\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df['Patient_ID'] = df['Tumor_Sample_Barcode'].apply(standardize_patient_id)\n",
    "    \n",
    "    # Map variant classifications to impact scores\n",
    "    df['Impact_Score'] = df['Variant_Classification'].map(variant_impact).fillna(0)\n",
    "    \n",
    "    # Aggregate mutations per patient-gene pair (take maximum impact)\n",
    "    mutation_matrix = df.groupby(['Patient_ID', 'Hugo_Symbol'])['Impact_Score'].max().unstack(fill_value=0)\n",
    "    \n",
    "    print(f\"Mutation matrix: {mutation_matrix.shape[0]} patients × {mutation_matrix.shape[1]} genes (impact scores)\")\n",
    "    \n",
    "    return mutation_matrix\n",
    "\n",
    "def load_clinical_data(file_path):\n",
    "    \"\"\"Load and preprocess clinical data\"\"\"\n",
    "    print(\"Loading clinical data...\")\n",
    "    \n",
    "    # Try different encodings to handle problematic characters\n",
    "    encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "    \n",
    "    df = None\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep='\\t', encoding=encoding, low_memory=False)\n",
    "            print(f\"Successfully loaded clinical data with {encoding} encoding\")\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    \n",
    "    if df is None:\n",
    "        # Last resort: ignore problematic characters\n",
    "        df = pd.read_csv(file_path, sep='\\t', encoding='utf-8', errors='ignore', low_memory=False)\n",
    "        print(\"Loaded clinical data with UTF-8 encoding, ignoring problematic characters\")\n",
    "    \n",
    "    # Standardize patient IDs\n",
    "    df['bcr_patient_barcode'] = df['bcr_patient_barcode'].apply(standardize_patient_id)\n",
    "    \n",
    "    # Set patient ID as index\n",
    "    df = df.set_index('bcr_patient_barcode')\n",
    "    \n",
    "    print(f\"Clinical data loaded: {df.shape[0]} patients × {df.shape[1]} features\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_survival_data(clinical_df):\n",
    "    \"\"\"생존 데이터를 정리하여 올바른 숫자형으로 변환\"\"\"\n",
    "    \n",
    "    print(\"=== 생존 데이터 정리 ===\")\n",
    "    print()\n",
    "    \n",
    "    clinical_clean = clinical_df.copy()\n",
    "    \n",
    "    # 1. days_to_death 정리\n",
    "    print(\"1. days_to_death 정리:\")\n",
    "    death_col = clinical_clean['days_to_death'].copy()\n",
    "    \n",
    "    # 비수치 값들을 NaN으로 변환\n",
    "    invalid_death = death_col.isin(['[Not Applicable]', '[Not Available]', '[Discrepancy]', '[Unknown]'])\n",
    "    print(f\"   • 비수치 값: {invalid_death.sum()}개 → NaN으로 변환\")\n",
    "    \n",
    "    death_col[invalid_death] = np.nan\n",
    "    death_col = pd.to_numeric(death_col, errors='coerce')\n",
    "    clinical_clean['days_to_death_clean'] = death_col\n",
    "    \n",
    "    # 2. days_to_last_followup 정리\n",
    "    print(\"2. days_to_last_followup 정리:\")\n",
    "    followup_col = clinical_clean['days_to_last_followup'].copy()\n",
    "    \n",
    "    invalid_followup = followup_col.isin(['[Not Applicable]', '[Not Available]', '[Discrepancy]', '[Unknown]'])\n",
    "    print(f\"   • 비수치 값: {invalid_followup.sum()}개 → NaN으로 변환\")\n",
    "    \n",
    "    followup_col[invalid_followup] = np.nan\n",
    "    followup_col = pd.to_numeric(followup_col, errors='coerce')\n",
    "    \n",
    "    # 음수값 제거 (잘못된 데이터)\n",
    "    negative_followup = followup_col < 0\n",
    "    print(f\"   • 음수 값: {negative_followup.sum()}개 → NaN으로 변환\")\n",
    "    followup_col[negative_followup] = np.nan\n",
    "    \n",
    "    clinical_clean['days_to_last_followup_clean'] = followup_col\n",
    "    \n",
    "    # 3. vital_status 정리\n",
    "    print(\"3. vital_status 정리:\")\n",
    "    vital_status_counts = clinical_clean['vital_status'].value_counts()\n",
    "    print(f\"   • {vital_status_counts.to_dict()}\")\n",
    "    \n",
    "    # 올바른 vital_status만 유지\n",
    "    valid_vital_status = clinical_clean['vital_status'].isin(['Alive', 'Dead'])\n",
    "    print(f\"   • 유효한 vital_status: {valid_vital_status.sum()}개\")\n",
    "    \n",
    "    # 4. 새로운 생존 시간과 이벤트 생성\n",
    "    print(\"4. 새로운 survival_time과 survival_event 생성:\")\n",
    "    \n",
    "    # survival_time 재계산\n",
    "    survival_time_new = np.where(\n",
    "        (clinical_clean['vital_status'] == 'Dead') & clinical_clean['days_to_death_clean'].notna(),\n",
    "        clinical_clean['days_to_death_clean'],\n",
    "        clinical_clean['days_to_last_followup_clean']\n",
    "    )\n",
    "    \n",
    "    # survival_event 재계산\n",
    "    survival_event_new = (clinical_clean['vital_status'] == 'Dead').astype(int)\n",
    "    \n",
    "    # 유효하지 않은 vital_status는 제외\n",
    "    survival_event_new[~valid_vital_status] = np.nan\n",
    "    survival_time_new[~valid_vital_status] = np.nan\n",
    "    \n",
    "    clinical_clean['survival_time_clean'] = survival_time_new\n",
    "    clinical_clean['survival_event_clean'] = survival_event_new\n",
    "    \n",
    "    # 5. 유효한 생존 데이터만 남기기\n",
    "    valid_survival = (\n",
    "        pd.notna(clinical_clean['survival_time_clean']) & \n",
    "        pd.notna(clinical_clean['survival_event_clean']) &\n",
    "        (clinical_clean['survival_time_clean'] >= 0)\n",
    "    )\n",
    "    \n",
    "    print(f\"   • 유효한 생존 데이터: {valid_survival.sum()}개\")\n",
    "    print(f\"   • 사망 이벤트: {clinical_clean.loc[valid_survival, 'survival_event_clean'].sum()}개\")\n",
    "    print(f\"   • 평균 생존 시간: {clinical_clean.loc[valid_survival, 'survival_time_clean'].mean():.1f}일\")\n",
    "    \n",
    "    return clinical_clean, valid_survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING TCGA PANCAN MULTI-OMICS DATA\n",
      "============================================================\n",
      "Loading transcriptome data...\n",
      "Gene symbols not split - using original index\n",
      "Transcriptome data loaded: 10327 patients × 20531 genes (log2 transformed)\n",
      "Loading CNV data...\n",
      "Applied log2(x - -1.290 + 1) transformation for negative CNV values\n",
      "CNV data loaded: 10713 patients × 25128 genes (log2 transformed)\n",
      "Loading microRNA data...\n",
      "microRNA data loaded: 9350 patients × 1071 miRNAs (log2 transformed)\n",
      "Loading RPPA data...\n",
      "Applied log2(x + 1) transformation\n",
      "RPPA data loaded: 7656 patients × 387 proteins (log2 transformed)\n",
      "Loading methylation data...\n",
      "Note: NO log2 transformation applied - beta values (0-1) for tab-transformer\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING TCGA PANCAN MULTI-OMICS DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load transcriptome data (log2 transformed)\n",
    "expression_data, transformation_stats = load_transcriptome_data(\n",
    "    DATA_RAW_PATH / 'unc.edu_PANCAN_IlluminaHiSeq_RNASeqV2.geneExp_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load CNV data (log2 transformed)\n",
    "cnv_data = load_cnv_data(\n",
    "    DATA_RAW_PATH / 'CNV.GISTIC_call.all_data_by_genes_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load microRNA data (log2 transformed)\n",
    "mirna_data = load_mirna_data(\n",
    "    DATA_RAW_PATH / 'bcgsc.ca_PANCAN_IlluminaHiSeq_miRNASeq.miRNAExp_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load RPPA data (log2 transformed)\n",
    "rppa_data = load_rppa_data(\n",
    "    DATA_RAW_PATH / 'mdanderson.org_PANCAN_MDA_RPPA_Core.RPPA_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load methylation data (NO transformation - for tab-transformer)\n",
    "methylation_data = load_methylation_data(\n",
    "    DATA_RAW_PATH / 'jhu-usc.edu_PANCAN_HumanMethylation450.betaValue_whitelisted.tsv'\n",
    ")\n",
    "\n",
    "# Load mutation data (impact scores - NO transformation)\n",
    "mutation_data = load_mutation_data(\n",
    "    DATA_RAW_PATH / 'tcga_pancancer_082115.vep.filter_whitelisted.maf.gz'\n",
    ")\n",
    "\n",
    "# Load clinical data\n",
    "clinical_data = load_clinical_data(\n",
    "    DATA_RAW_PATH / 'clinical_PANCAN_patient_with_followup.tsv'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA LOADING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Expression: {expression_data.shape[0]} patients × {expression_data.shape[1]} genes (log2 transformed)\")\n",
    "print(f\"CNV: {cnv_data.shape[0]} patients × {cnv_data.shape[1]} genes (log2 transformed)\")\n",
    "print(f\"microRNA: {mirna_data.shape[0]} patients × {mirna_data.shape[1]} miRNAs (log2 transformed)\")\n",
    "print(f\"RPPA: {rppa_data.shape[0]} patients × {rppa_data.shape[1]} proteins (log2 transformed)\")\n",
    "print(f\"Methylation: {methylation_data.shape[0]} patients × {methylation_data.shape[1]} probes (NO transformation)\")\n",
    "print(f\"Mutations: {mutation_data.shape[0]} patients × {mutation_data.shape[1]} genes (impact scores)\")\n",
    "print(f\"Clinical: {clinical_data.shape[0]} patients × {clinical_data.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Survival Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생존 데이터 정리 실행\n",
    "clinical_data_clean, valid_survival_mask = clean_survival_data(clinical_data)\n",
    "\n",
    "print()\n",
    "print(\"=== 정리 후 검증 ===\")\n",
    "print(f\"전체 환자: {len(clinical_data_clean)}\")\n",
    "print(f\"유효한 생존 데이터 보유 환자: {valid_survival_mask.sum()}\")\n",
    "\n",
    "# 유효한 생존 데이터를 가진 환자 목록\n",
    "valid_survival_patients = clinical_data_clean.index[valid_survival_mask]\n",
    "print(f\"유효한 생존 데이터 환자 목록: {len(valid_survival_patients)}명\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Patient ID Matching and Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patient overlap across datasets\n",
    "datasets = {\n",
    "    'Expression': set(expression_data.index),\n",
    "    'CNV': set(cnv_data.index),\n",
    "    'microRNA': set(mirna_data.index),\n",
    "    'RPPA': set(rppa_data.index),\n",
    "    'Methylation': set(methylation_data.index),\n",
    "    'Mutations': set(mutation_data.index),\n",
    "    'Clinical': set(valid_survival_patients)  # Only valid survival patients\n",
    "}\n",
    "\n",
    "print(\"Patient counts per dataset:\")\n",
    "for name, patients in datasets.items():\n",
    "    print(f\"{name}: {len(patients)} patients\")\n",
    "\n",
    "# Find common patients across all datasets (including methylation)\n",
    "common_all_datasets = set.intersection(*datasets.values())\n",
    "print(f\"\\nCommon patients across ALL datasets (including methylation): {len(common_all_datasets)}\")\n",
    "\n",
    "# Find common patients excluding methylation (for Cox analysis)\n",
    "cox_datasets = {k: v for k, v in datasets.items() if k != 'Methylation'}\n",
    "common_cox_patients = set.intersection(*cox_datasets.values())\n",
    "print(f\"Common patients for Cox analysis (excluding methylation): {len(common_cox_patients)}\")\n",
    "\n",
    "# Convert to sorted lists for pandas indexing\n",
    "final_all_patients = sorted(list(common_all_datasets))\n",
    "final_cox_patients = sorted(list(common_cox_patients))\n",
    "\n",
    "print(f\"\\n=== 정리 후 검증 ===\")\n",
    "print(f\"전체 데이터셋 공통 환자: {len(final_all_patients)}\")\n",
    "print(f\"Cox 분석 대상 환자: {len(final_cox_patients)}\")\n",
    "print(f\"메틸레이션 데이터 (tab-transformer용): {len(final_all_patients)} 환자\")\n",
    "\n",
    "# 최종 분석 대상 환자 리스트 \n",
    "final_patient_list_clean = final_cox_patients\n",
    "print(f\"최종 Cox 분석 대상: {len(final_patient_list_clean)} 환자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data quality visualization\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Plot patient counts\n",
    "plt.subplot(3, 3, 1)\n",
    "dataset_counts = [len(patients) for patients in datasets.values()]\n",
    "plt.bar(range(len(datasets)), dataset_counts, color='skyblue')\n",
    "plt.xticks(range(len(datasets)), list(datasets.keys()), rotation=45)\n",
    "plt.title('Patient Counts by Dataset')\n",
    "plt.ylabel('Number of Patients')\n",
    "for i, count in enumerate(dataset_counts):\n",
    "    plt.text(i, count + 50, str(count), ha='center')\n",
    "\n",
    "# Plot cancer type distribution\n",
    "if 'acronym' in clinical_data_clean.columns:\n",
    "    plt.subplot(3, 3, 2)\n",
    "    cancer_counts = clinical_data_clean.loc[final_cox_patients, 'acronym'].value_counts()\n",
    "    cancer_counts.head(15).plot(kind='bar', color='lightcoral')\n",
    "    plt.title('Cancer Types (Cox Analysis Patients)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Patient Count')\n",
    "\n",
    "# Plot survival data quality\n",
    "plt.subplot(3, 3, 3)\n",
    "survival_times = clinical_data_clean.loc[final_cox_patients, 'survival_time_clean']\n",
    "plt.hist(survival_times.dropna(), bins=50, alpha=0.7, color='lightgreen')\n",
    "plt.title('Survival Time Distribution')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Patient Count')\n",
    "\n",
    "# Plot survival events\n",
    "plt.subplot(3, 3, 4)\n",
    "event_counts = clinical_data_clean.loc[final_cox_patients, 'survival_event_clean'].value_counts()\n",
    "plt.pie(event_counts.values, labels=['Censored', 'Death'], autopct='%1.1f%%', colors=['lightblue', 'salmon'])\n",
    "plt.title('Survival Events')\n",
    "\n",
    "# Plot dataset overlap\n",
    "plt.subplot(3, 3, 5)\n",
    "overlap_data = {\n",
    "    'All datasets\\n(w/ methylation)': len(final_all_patients),\n",
    "    'Cox datasets\\n(no methylation)': len(final_cox_patients),\n",
    "    'Valid survival': len(valid_survival_patients)\n",
    "}\n",
    "plt.bar(overlap_data.keys(), overlap_data.values(), color=['gold', 'darkblue', 'green'])\n",
    "plt.title('Patient Overlap Analysis')\n",
    "plt.ylabel('Number of Patients')\n",
    "for i, (key, value) in enumerate(overlap_data.items()):\n",
    "    plt.text(i, value + 20, str(value), ha='center')\n",
    "\n",
    "# Plot transformation comparison for expression data\n",
    "plt.subplot(3, 3, 6)\n",
    "original_mean = transformation_stats['original']['mean']\n",
    "transformed_mean = transformation_stats['transformed']['mean']\n",
    "plt.bar(['Original', 'Log2+1'], [original_mean, transformed_mean], color=['orange', 'purple'])\n",
    "plt.title('Expression Data Transformation')\n",
    "plt.ylabel('Mean Value')\n",
    "\n",
    "# Plot methylation data characteristics\n",
    "plt.subplot(3, 3, 7)\n",
    "meth_sample = methylation_data.loc[final_all_patients[:100]].values.flatten()\n",
    "meth_sample_clean = meth_sample[~np.isnan(meth_sample)]\n",
    "plt.hist(meth_sample_clean[:10000], bins=50, alpha=0.7, color='magenta')\n",
    "plt.title('Methylation Beta Values Distribution\\n(Sample)')\n",
    "plt.xlabel('Beta Value (0-1)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Plot data completeness heatmap\n",
    "plt.subplot(3, 3, 8)\n",
    "completeness_matrix = []\n",
    "dataset_names = list(datasets.keys())\n",
    "for i, (name1, patients1) in enumerate(datasets.items()):\n",
    "    row = []\n",
    "    for j, (name2, patients2) in enumerate(datasets.items()):\n",
    "        if i == j:\n",
    "            overlap = 1.0\n",
    "        else:\n",
    "            intersection = len(patients1.intersection(patients2))\n",
    "            union = len(patients1.union(patients2))\n",
    "            overlap = intersection / union if union > 0 else 0\n",
    "        row.append(overlap)\n",
    "    completeness_matrix.append(row)\n",
    "\n",
    "im = plt.imshow(completeness_matrix, cmap='Blues', vmin=0, vmax=1)\n",
    "plt.xticks(range(len(dataset_names)), dataset_names, rotation=45)\n",
    "plt.yticks(range(len(dataset_names)), dataset_names)\n",
    "plt.title('Dataset Overlap Matrix')\n",
    "plt.colorbar(im, shrink=0.6)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(dataset_names)):\n",
    "    for j in range(len(dataset_names)):\n",
    "        plt.text(j, i, f'{completeness_matrix[i][j]:.2f}',\n",
    "                ha='center', va='center', color='black' if completeness_matrix[i][j] < 0.5 else 'white')\n",
    "\n",
    "# Plot missing data analysis\n",
    "plt.subplot(3, 3, 9)\n",
    "missing_data = {\n",
    "    'Methylation': (methylation_data.isna().sum().sum() / (methylation_data.shape[0] * methylation_data.shape[1])) * 100\n",
    "}\n",
    "plt.bar(missing_data.keys(), missing_data.values(), color='red', alpha=0.7)\n",
    "plt.title('Missing Data Percentage')\n",
    "plt.ylabel('Missing Data (%)')\n",
    "for i, (key, value) in enumerate(missing_data.items()):\n",
    "    plt.text(i, value + 0.1, f'{value:.1f}%', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display transformation statistics\n",
    "print(f\"\\nExpression Data Transformation Statistics:\")\n",
    "print(f\"Original data - Mean: {transformation_stats['original']['mean']:.3f}, Std: {transformation_stats['original']['std']:.3f}\")\n",
    "print(f\"Transformed data - Mean: {transformation_stats['transformed']['mean']:.3f}, Std: {transformation_stats['transformed']['std']:.3f}\")\n",
    "print(f\"Zero values - Original: {transformation_stats['original']['zeros']}, Transformed: {transformation_stats['transformed']['zeros']}\")\n",
    "\n",
    "print(f\"\\nData Integration Summary:\")\n",
    "print(f\"• Total datasets: {len(datasets)}\")\n",
    "print(f\"• Log2 transformed: Expression, CNV, microRNA, RPPA\")\n",
    "print(f\"• NO transformation: Methylation (beta values), Mutations (impact scores)\")\n",
    "print(f\"• Cox analysis patients: {len(final_cox_patients)}\")\n",
    "print(f\"• Tab-transformer patients (with methylation): {len(final_all_patients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cox Regression Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cox_regression_by_cancer(omics_data, clinical_data, omics_type, min_patients=20, p_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Perform Cox regression analysis by cancer type for given omics data\n",
    "    \n",
    "    Parameters:\n",
    "    - omics_data: DataFrame with patients as rows, features as columns\n",
    "    - clinical_data: DataFrame with survival information\n",
    "    - omics_type: String identifier for the omics type\n",
    "    - min_patients: Minimum number of patients required per cancer type\n",
    "    - p_threshold: P-value threshold for significance\n",
    "    \n",
    "    Returns:\n",
    "    - cox_results: Dictionary with results by cancer type\n",
    "    - summary_stats: Overall summary statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nPerforming Cox regression analysis for {omics_type} data...\")\n",
    "    \n",
    "    # Filter for common patients\n",
    "    common_patients = list(set(omics_data.index).intersection(set(clinical_data.index)))\n",
    "    \n",
    "    # Get survival data for common patients (use cleaned survival data)\n",
    "    survival_data = clinical_data.loc[common_patients, ['survival_time_clean', 'survival_event_clean', 'acronym']].copy()\n",
    "    survival_data = survival_data.dropna()\n",
    "    \n",
    "    # Filter omics data for patients with survival data\n",
    "    omics_filtered = omics_data.loc[survival_data.index].copy()\n",
    "    \n",
    "    print(f\"Analysis dataset: {len(survival_data)} patients with {omics_filtered.shape[1]} features\")\n",
    "    \n",
    "    # Group by cancer type\n",
    "    cancer_types = survival_data['acronym'].value_counts()\n",
    "    valid_cancers = cancer_types[cancer_types >= min_patients].index\n",
    "    \n",
    "    print(f\"Cancer types with >= {min_patients} patients: {len(valid_cancers)}\")\n",
    "    \n",
    "    cox_results = {}\n",
    "    summary_stats = {\n",
    "        'total_features': omics_filtered.shape[1],\n",
    "        'total_patients': len(survival_data),\n",
    "        'cancer_types': len(valid_cancers),\n",
    "        'significant_features': {},\n",
    "        'top_features': {}\n",
    "    }\n",
    "    \n",
    "    for cancer in tqdm(valid_cancers, desc=f\"Processing {omics_type}\"):\n",
    "        # Get patients for this cancer type\n",
    "        cancer_patients = survival_data[survival_data['acronym'] == cancer].index\n",
    "        \n",
    "        # Get omics and survival data for this cancer\n",
    "        cancer_omics = omics_filtered.loc[cancer_patients]\n",
    "        cancer_survival = survival_data.loc[cancer_patients, ['survival_time_clean', 'survival_event_clean']]\n",
    "        \n",
    "        # Remove features with zero variance\n",
    "        feature_vars = cancer_omics.var()\n",
    "        valid_features = feature_vars[feature_vars > 0].index\n",
    "        cancer_omics_filtered = cancer_omics[valid_features]\n",
    "        \n",
    "        print(f\"\\n{cancer}: {len(cancer_patients)} patients, {len(valid_features)} variable features\")\n",
    "        \n",
    "        # Perform univariate Cox regression for each feature\n",
    "        feature_results = []\n",
    "        \n",
    "        for feature in valid_features:\n",
    "            try:\n",
    "                # Create dataframe for Cox regression\n",
    "                cox_data = pd.DataFrame({\n",
    "                    'T': cancer_survival['survival_time_clean'],\n",
    "                    'E': cancer_survival['survival_event_clean'],\n",
    "                    feature: cancer_omics_filtered[feature]\n",
    "                })\n",
    "                \n",
    "                # Remove rows with missing data\n",
    "                cox_data = cox_data.dropna()\n",
    "                \n",
    "                if len(cox_data) < 5:  # Need at least 5 observations\n",
    "                    continue\n",
    "                \n",
    "                # Fit Cox model\n",
    "                cph = CoxPHFitter()\n",
    "                cph.fit(cox_data, duration_col='T', event_col='E')\n",
    "                \n",
    "                # Extract results\n",
    "                coef = cph.summary.loc[feature, 'coef']\n",
    "                p_value = cph.summary.loc[feature, 'p']\n",
    "                hr = np.exp(coef)\n",
    "                ci_lower = np.exp(cph.summary.loc[feature, 'coef lower 95%'])\n",
    "                ci_upper = np.exp(cph.summary.loc[feature, 'coef upper 95%'])\n",
    "                \n",
    "                feature_results.append({\n",
    "                    'feature': feature,\n",
    "                    'coef': coef,\n",
    "                    'hr': hr,\n",
    "                    'p_value': p_value,\n",
    "                    'ci_lower': ci_lower,\n",
    "                    'ci_upper': ci_upper,\n",
    "                    'n_patients': len(cox_data)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Skip problematic features\n",
    "                continue\n",
    "        \n",
    "        # Convert to DataFrame and sort by p-value\n",
    "        if feature_results:\n",
    "            results_df = pd.DataFrame(feature_results)\n",
    "            results_df = results_df.sort_values('p_value')\n",
    "            \n",
    "            # Count significant features\n",
    "            significant_count = sum(results_df['p_value'] < p_threshold)\n",
    "            \n",
    "            cox_results[cancer] = results_df\n",
    "            summary_stats['significant_features'][cancer] = significant_count\n",
    "            summary_stats['top_features'][cancer] = results_df.head(10)\n",
    "            \n",
    "            print(f\"  Significant features (p < {p_threshold}): {significant_count}/{len(results_df)}\")\n",
    "        else:\n",
    "            print(f\"  No valid results for {cancer}\")\n",
    "    \n",
    "    return cox_results, summary_stats\n",
    "\n",
    "def create_cox_coefficient_lookup(cox_results_dict, omics_types):\n",
    "    \"\"\"Create a comprehensive Cox coefficient lookup table\"\"\"\n",
    "    \n",
    "    print(\"\\nCreating Cox coefficient lookup tables...\")\n",
    "    \n",
    "    # Initialize lookup dictionary\n",
    "    lookup_tables = {}\n",
    "    \n",
    "    for omics_type in omics_types:\n",
    "        if omics_type in cox_results_dict:\n",
    "            print(f\"\\nProcessing {omics_type} results...\")\n",
    "            \n",
    "            # Combine all cancer type results\n",
    "            all_results = []\n",
    "            \n",
    "            for cancer, results_df in cox_results_dict[omics_type].items():\n",
    "                if not results_df.empty:\n",
    "                    results_copy = results_df.copy()\n",
    "                    results_copy['cancer_type'] = cancer\n",
    "                    results_copy['omics_type'] = omics_type\n",
    "                    all_results.append(results_copy)\n",
    "            \n",
    "            if all_results:\n",
    "                combined_df = pd.concat(all_results, ignore_index=True)\n",
    "                \n",
    "                # Create pivot table: features × cancer_types with coefficients\n",
    "                pivot_coef = combined_df.pivot_table(\n",
    "                    index='feature', \n",
    "                    columns='cancer_type', \n",
    "                    values='coef', \n",
    "                    fill_value=0\n",
    "                )\n",
    "                \n",
    "                # Create pivot table for p-values\n",
    "                pivot_pval = combined_df.pivot_table(\n",
    "                    index='feature', \n",
    "                    columns='cancer_type', \n",
    "                    values='p_value', \n",
    "                    fill_value=1\n",
    "                )\n",
    "                \n",
    "                # Create summary statistics per feature\n",
    "                feature_stats = combined_df.groupby('feature').agg({\n",
    "                    'coef': ['mean', 'std', 'count'],\n",
    "                    'p_value': ['min', 'mean'],\n",
    "                    'hr': ['mean']\n",
    "                }).round(4)\n",
    "                \n",
    "                # Flatten column names\n",
    "                feature_stats.columns = ['_'.join(col).strip() for col in feature_stats.columns]\n",
    "                \n",
    "                lookup_tables[omics_type] = {\n",
    "                    'coefficients': pivot_coef,\n",
    "                    'p_values': pivot_pval,\n",
    "                    'feature_stats': feature_stats,\n",
    "                    'raw_results': combined_df\n",
    "                }\n",
    "                \n",
    "                print(f\"  {omics_type}: {len(pivot_coef)} features across {len(pivot_coef.columns)} cancer types\")\n",
    "    \n",
    "    return lookup_tables\n",
    "\n",
    "def visualize_cox_results(cox_results, omics_type, top_n=20):\n",
    "    \"\"\"Visualize Cox regression results\"\"\"\n",
    "    \n",
    "    # Combine results across cancer types\n",
    "    all_results = []\n",
    "    for cancer, results_df in cox_results.items():\n",
    "        if not results_df.empty:\n",
    "            results_copy = results_df.copy()\n",
    "            results_copy['cancer_type'] = cancer\n",
    "            all_results.append(results_copy)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(f\"No results to visualize for {omics_type}\")\n",
    "        return\n",
    "    \n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(f'Cox Regression Results: {omics_type}', fontsize=16)\n",
    "    \n",
    "    # 1. P-value distribution\n",
    "    axes[0, 0].hist(combined_df['p_value'], bins=50, alpha=0.7)\n",
    "    axes[0, 0].axvline(x=0.05, color='red', linestyle='--', label='p=0.05')\n",
    "    axes[0, 0].set_xlabel('P-value')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('P-value Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Coefficient distribution\n",
    "    axes[0, 1].hist(combined_df['coef'], bins=50, alpha=0.7)\n",
    "    axes[0, 1].axvline(x=0, color='red', linestyle='--', label='coef=0')\n",
    "    axes[0, 1].set_xlabel('Cox Coefficient')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Coefficient Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # 3. Top significant features\n",
    "    significant_features = combined_df[combined_df['p_value'] < 0.05]\n",
    "    if len(significant_features) > 0:\n",
    "        top_features = significant_features.nsmallest(top_n, 'p_value')\n",
    "        \n",
    "        # Create a color map for cancer types\n",
    "        cancer_types = top_features['cancer_type'].unique()\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(cancer_types)))\n",
    "        color_map = dict(zip(cancer_types, colors))\n",
    "        \n",
    "        scatter_colors = [color_map[cancer] for cancer in top_features['cancer_type']]\n",
    "        \n",
    "        scatter = axes[1, 0].scatter(top_features['coef'], -np.log10(top_features['p_value']), \n",
    "                                   c=scatter_colors, alpha=0.7)\n",
    "        axes[1, 0].axhline(y=-np.log10(0.05), color='red', linestyle='--', label='p=0.05')\n",
    "        axes[1, 0].axvline(x=0, color='red', linestyle='--')\n",
    "        axes[1, 0].set_xlabel('Cox Coefficient')\n",
    "        axes[1, 0].set_ylabel('-log10(p-value)')\n",
    "        axes[1, 0].set_title(f'Top {top_n} Significant Features')\n",
    "        \n",
    "        # Add legend for cancer types\n",
    "        legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                    markerfacecolor=color_map[cancer], markersize=8, label=cancer)\n",
    "                         for cancer in cancer_types[:10]]  # Limit legend size\n",
    "        axes[1, 0].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # 4. Significant features by cancer type\n",
    "    cancer_sig_counts = combined_df[combined_df['p_value'] < 0.05]['cancer_type'].value_counts()\n",
    "    if len(cancer_sig_counts) > 0:\n",
    "        cancer_sig_counts.head(15).plot(kind='bar', ax=axes[1, 1])\n",
    "        axes[1, 1].set_xlabel('Cancer Type')\n",
    "        axes[1, 1].set_ylabel('Significant Features')\n",
    "        axes[1, 1].set_title('Significant Features by Cancer')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    total_tests = len(combined_df)\n",
    "    significant_tests = len(combined_df[combined_df['p_value'] < 0.05])\n",
    "    \n",
    "    print(f\"\\n{omics_type} Summary:\")\n",
    "    print(f\"Total tests: {total_tests:,}\")\n",
    "    print(f\"Significant tests (p < 0.05): {significant_tests:,} ({100*significant_tests/total_tests:.1f}%)\")\n",
    "    print(f\"Cancer types analyzed: {combined_df['cancer_type'].nunique()}\")\n",
    "    print(f\"Unique features tested: {combined_df['feature'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Perform Cox Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare filtered datasets for analysis\n",
    "filtered_data = {}\n",
    "\n",
    "# Filter all datasets to common patients with survival data\n",
    "for name, data in [\n",
    "    ('Expression', expression_data),\n",
    "    ('CNV', cnv_data),\n",
    "    ('microRNA', mirna_data),\n",
    "    ('RPPA', rppa_data),\n",
    "    ('Mutations', mutation_data)\n",
    "]:\n",
    "    # Filter to common survival patients\n",
    "    common_patients_data = data.loc[final_patient_list_clean]\n",
    "    filtered_data[name] = common_patients_data\n",
    "    print(f\"{name}: {common_patients_data.shape[0]} patients × {common_patients_data.shape[1]} features\")\n",
    "\n",
    "# Also filter clinical data\n",
    "filtered_clinical = clinical_data_clean.loc[final_patient_list_clean]\n",
    "print(f\"Clinical: {filtered_clinical.shape[0]} patients × {filtered_clinical.shape[1]} features\")\n",
    "\n",
    "print(f\"\\\\nAll datasets now have {len(final_patient_list_clean)} patients with complete omics and survival data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Cox regression analysis for each omics type\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMING COX REGRESSION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Store all results\n",
    "all_cox_results = {}\n",
    "all_summary_stats = {}\n",
    "\n",
    "# Define omics types and their corresponding data\n",
    "omics_data_map = {\n",
    "    'Expression': filtered_data['Expression'],\n",
    "    'CNV': filtered_data['CNV'],\n",
    "    'microRNA': filtered_data['microRNA'],\n",
    "    'RPPA': filtered_data['RPPA'],\n",
    "    'Mutations': filtered_data['Mutations']\n",
    "}\n",
    "\n",
    "# Run Cox regression for each omics type\n",
    "for omics_type, omics_data in omics_data_map.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing {omics_type}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Perform Cox regression analysis\n",
    "    cox_results, summary_stats = perform_cox_regression_by_cancer(\n",
    "        omics_data=omics_data,\n",
    "        clinical_data=filtered_clinical,\n",
    "        omics_type=omics_type,\n",
    "        min_patients=20,  # Minimum 20 patients per cancer type\n",
    "        p_threshold=0.05\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    all_cox_results[omics_type] = cox_results\n",
    "    all_summary_stats[omics_type] = summary_stats\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\n{omics_type} Analysis Summary:\")\n",
    "    print(f\"  Total features analyzed: {summary_stats['total_features']:,}\")\n",
    "    print(f\"  Total patients: {summary_stats['total_patients']:,}\")\n",
    "    print(f\"  Cancer types analyzed: {summary_stats['cancer_types']}\")\n",
    "    \n",
    "    # Display significant features by cancer type\n",
    "    if summary_stats['significant_features']:\n",
    "        print(f\"  Significant features by cancer type:\")\n",
    "        for cancer, count in summary_stats['significant_features'].items():\n",
    "            print(f\"    {cancer}: {count} significant features\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"COX REGRESSION ANALYSIS COMPLETED\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create Cox Coefficient Lookup Tables and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive lookup tables\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREATING COX COEFFICIENT LOOKUP TABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create lookup tables for all omics types\n",
    "omics_types = list(all_cox_results.keys())\n",
    "lookup_tables = create_cox_coefficient_lookup(all_cox_results, omics_types)\n",
    "\n",
    "# Visualize results for each omics type\n",
    "for omics_type in omics_types:\n",
    "    if omics_type in all_cox_results and all_cox_results[omics_type]:\n",
    "        print(f\"\\nVisualizing {omics_type} results...\")\n",
    "        visualize_cox_results(all_cox_results[omics_type], omics_type, top_n=20)\n",
    "\n",
    "# Save all results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING PROCESSED DATA AND RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save lookup tables\n",
    "for omics_type, tables in lookup_tables.items():\n",
    "    # Save coefficient matrix\n",
    "    coef_file = DATA_PROCESSED_PATH / f'cox_coefficients_{omics_type.lower()}.parquet'\n",
    "    tables['coefficients'].to_parquet(coef_file)\n",
    "    print(f\"Saved {omics_type} coefficients: {coef_file}\")\n",
    "    \n",
    "    # Save p-values matrix\n",
    "    pval_file = DATA_PROCESSED_PATH / f'cox_pvalues_{omics_type.lower()}.parquet'\n",
    "    tables['p_values'].to_parquet(pval_file)\n",
    "    print(f\"Saved {omics_type} p-values: {pval_file}\")\n",
    "    \n",
    "    # Save feature statistics\n",
    "    stats_file = DATA_PROCESSED_PATH / f'cox_feature_stats_{omics_type.lower()}.parquet'\n",
    "    tables['feature_stats'].to_parquet(stats_file)\n",
    "    print(f\"Saved {omics_type} feature stats: {stats_file}\")\n",
    "    \n",
    "    # Save raw results\n",
    "    raw_file = DATA_PROCESSED_PATH / f'cox_raw_results_{omics_type.lower()}.parquet'\n",
    "    tables['raw_results'].to_parquet(raw_file)\n",
    "    print(f\"Saved {omics_type} raw results: {raw_file}\")\n",
    "\n",
    "# Save processed omics data\n",
    "for omics_type, data in filtered_data.items():\n",
    "    processed_file = DATA_PROCESSED_PATH / f'processed_{omics_type.lower()}_data.parquet'\n",
    "    data.to_parquet(processed_file)\n",
    "    print(f\"Saved processed {omics_type} data: {processed_file}\")\n",
    "\n",
    "# Save methylation data separately for tab-transformer\n",
    "methylation_file = DATA_PROCESSED_PATH / 'methylation_data_for_tabtransformer.parquet'\n",
    "# Filter methylation data to common patients\n",
    "if len(final_all_patients) > 0:\n",
    "    methylation_filtered = methylation_data.loc[final_all_patients]\n",
    "    methylation_filtered.to_parquet(methylation_file)\n",
    "    print(f\"Saved methylation data for tab-transformer: {methylation_file}\")\n",
    "    print(f\"  Shape: {methylation_filtered.shape[0]} patients × {methylation_filtered.shape[1]} probes\")\n",
    "    print(f\"  Beta values preserved (0-1 range) for tab-transformer network\")\n",
    "else:\n",
    "    print(\"Warning: No common patients found for methylation data\")\n",
    "\n",
    "# Save processed clinical data\n",
    "clinical_file = DATA_PROCESSED_PATH / 'processed_clinical_data.parquet'\n",
    "filtered_clinical.to_parquet(clinical_file)\n",
    "print(f\"Saved processed clinical data: {clinical_file}\")\n",
    "\n",
    "# Save analysis summary\n",
    "summary_file = RESULTS_PATH / 'cox_analysis_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    # Convert numpy types to native Python types for JSON serialization\n",
    "    summary_for_json = {}\n",
    "    for omics_type, stats in all_summary_stats.items():\n",
    "        summary_for_json[omics_type] = {\n",
    "            'total_features': int(stats['total_features']),\n",
    "            'total_patients': int(stats['total_patients']),\n",
    "            'cancer_types': int(stats['cancer_types']),\n",
    "            'significant_features': {k: int(v) for k, v in stats['significant_features'].items()}\n",
    "        }\n",
    "    \n",
    "    json.dump(summary_for_json, f, indent=2)\n",
    "print(f\"Saved analysis summary: {summary_file}\")\n",
    "\n",
    "# Save transformation statistics\n",
    "transform_file = RESULTS_PATH / 'transformation_stats.json'\n",
    "with open(transform_file, 'w') as f:\n",
    "    # Convert numpy types to native Python types\n",
    "    transform_for_json = {}\n",
    "    for key, value in transformation_stats.items():\n",
    "        if isinstance(value, dict):\n",
    "            transform_for_json[key] = {k: float(v) for k, v in value.items()}\n",
    "        else:\n",
    "            transform_for_json[key] = int(value) if isinstance(value, (int, np.integer)) else float(value)\n",
    "    \n",
    "    json.dump(transform_for_json, f, indent=2)\n",
    "print(f\"Saved transformation stats: {transform_file}\")\n",
    "\n",
    "# Save data processing metadata\n",
    "metadata = {\n",
    "    'data_processing_info': {\n",
    "        'total_datasets': len(datasets),\n",
    "        'log2_transformed': ['Expression', 'CNV', 'microRNA', 'RPPA'],\n",
    "        'no_transformation': ['Methylation', 'Mutations'],\n",
    "        'cox_analysis_patients': len(final_cox_patients),\n",
    "        'methylation_patients': len(final_all_patients),\n",
    "        'transformation_applied': 'log2(x+1) for Expression, CNV, microRNA, RPPA',\n",
    "        'methylation_note': 'Beta values (0-1) preserved for tab-transformer',\n",
    "        'mutation_note': 'Impact scores (0-2) for variant classification'\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_file = RESULTS_PATH / 'data_processing_metadata.json'\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"Saved data processing metadata: {metadata_file}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL DATA PROCESSING AND ANALYSIS COMPLETED!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Processed data saved to: {DATA_PROCESSED_PATH}\")\n",
    "print(f\"Analysis results saved to: {RESULTS_PATH}\")\n",
    "print(f\"Cox analysis patients: {len(final_patient_list_clean)}\")\n",
    "print(f\"Methylation data patients: {len(final_all_patients)}\")\n",
    "print(f\"Omics types processed: {', '.join(omics_types)}\")\n",
    "\n",
    "# Display final summary\n",
    "print(f\"\\nFinal Analysis Summary:\")\n",
    "for omics_type, stats in all_summary_stats.items():\n",
    "    total_significant = sum(stats['significant_features'].values())\n",
    "    print(f\"  {omics_type}:\")\n",
    "    print(f\"    - Features: {stats['total_features']:,}\")\n",
    "    print(f\"    - Cancer types: {stats['cancer_types']}\")\n",
    "    print(f\"    - Significant features: {total_significant:,}\")\n",
    "\n",
    "print(f\"\\nData Files Summary:\")\n",
    "print(f\"  Cox Regression Analysis:\")\n",
    "print(f\"    - Patients: {len(final_patient_list_clean)}\")\n",
    "print(f\"    - Omics types: Expression, CNV, microRNA, RPPA, Mutations\")\n",
    "print(f\"    - All data log2 transformed (except mutations)\")\n",
    "print(f\"  Tab-Transformer Data:\")\n",
    "print(f\"    - Patients: {len(final_all_patients)}\")\n",
    "print(f\"    - Methylation probes: {methylation_filtered.shape[1] if len(final_all_patients) > 0 else 0}\")\n",
    "print(f\"    - Beta values preserved (0-1 range)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
